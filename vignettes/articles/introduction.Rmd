---
title: "Introduction"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r prepare, include = FALSE}
# Restore the current instance at the end of the vignette
current_instance <- laminr::get_current_lamin_instance()
withr::defer(laminr::lamin_connect(current_instance))

# Restore the current user at the end of the vignette
current_user <- laminr::get_current_lamin_user()
laminr::lamin_logout()
withr::defer(laminr::lamin_login(current_user))

# Set up a temporary test instance
laminr::lamin_init_temp(name = "laminr-intro", modules = c("bionty"))

# Disconnect from this instance at the end of the vignette
withr::defer(laminr::lamin_disconnect())
```

This vignette introduces the **{laminr}** workflow.

To learn more about LaminDB, see [docs.lamin.ai](https://docs.lamin.ai).

# Quickstart

For setup, install the **{laminr}** and **lamindb** packages and connect to a LaminDB instance.

```r
install.packages("laminr", dependencies = TRUE)  # install the laminr package from CRAN
laminr::install_lamindb(extra_packages = c("bionty"))  # install lamindb & bionty for use via reticulate
laminr::lamin_login()  # <-- you can skip this for local & self-hosted instances
laminr::lamin_connect("<account>/<instance>")  # <-- replace with your instance
```

Here's how to create a local instance.

```r
laminr::lamin_init(storage = "./mydata", modules = c("bionty"))
```

In an R session, transfer an scRNA-seq dataset from the laminlabs/cellxgene instance, compute marker genes with Seurat, and save results.

```{r file = "../../test-docs/r-quickstart.R", eval = FALSE}
```

If you did not use RStudioâ€™s notebook mode, create an html export and then run the following.

```r
laminr::lamin_save("my-analyis.Rmd")  # save source code and html report for a `.qmd` or `.Rmd` file
```

# Track notebooks & scripts

See https://docs.lamin.ai/introduction#track-notebooks-scripts

```r
library(laminr)
lamin_init(storage = "./laminr-intro", modules = c("bionty"))
```

```{r track}
library(laminr)
ln <- import_module("lamindb")  # instantiate the central `ln` object of the API

ln$track()  # track a run of your notebook or script

ln$Transform$df()

ln$Run$df()
```

# Manage artifacts

See https://docs.lamin.ai/introduction#manage-artifacts

## Manage Dataframes

See https://docs.lamin.ai/introduction#manage-dataframes

```{r manage-artifacts}
df <- ln$core$datasets$small_dataset1(otype = "DataFrame", with_typo = TRUE)
df

artifact <- ln$Artifact$from_df(df, key = "my_datasets/rnaseq1.parquet")$save()
artifact$describe()

artifact$load()
```

## Trace data lineage

See https://docs.lamin.ai/introduction#trace-data-lineage

```{r trace-lineage}
artifact$transform

artifact$run

artifact$view_lineage()
```

```r
ln$finish()  # mark run as finished, save execution report & source code
```

## Manage versioning

See https://docs.lamin.ai/introduction#manage-versioning

```{r manage-versioing}
# keep the dataframe with a typo around - we'll need it later
df_typo <- df

# fix the "IFNJ" typo
levels(df$perturbation) <- c("DMSO", "IFNG")
df["sample2", "perturbation"] <- "IFNG"

# create a new version
artifact <- ln$Artifact$from_df(df, key = "my_datasets/rnaseq1.parquet")$save()

# see all versions of an artifact
artifact$versions$df()
```

```{r manage-versioning-revises}
artifact_v1 <- ln$Artifact$from_df(df, description = "Just a description")$save()
# below revises artifact_v1
df_updated <- df
df_updated[1, 1] <- 10
artifact_v2 <- ln$Artifact$from_df(df_updated, revises = artifact_v1)$save()
```

## Manage files & folders

See https://docs.lamin.ai/introduction#manage-files-folders

```{r manage-files}
# we use anon=True here in case no aws credentials are configured
ln$UPath("s3://lamindata/iris_studies", anon = TRUE)$view_tree()

artifact <- ln$Artifact("s3://lamindata/iris_studies/study0_raw_images")$save()
artifact

artifact$path

ln$Storage$df()

artifact$cache()
```

```{r manage-files-update}
artifact_update <- ln$Artifact$from_df(df, key = "my_datasets/rnaseq-update.parquet")$save()
artifact_update$description <- "My new description"  # change description
artifact_update$save()  # save the change to the database
artifact_update$delete()  # move to trash
artifact_update$delete(permanent = TRUE)  # permanently delete
```

# Query & search registries

See https://docs.lamin.ai/introduction#query-search-registries

```{r query}
ln$Artifact$df()

ln$Artifact

ln$view()

# get a single record (here the current notebook)
transform <- ln$Transform$get(key = "introduction.Rmd")

# get a set of records by filtering for a directory (LaminDB treats directories
# like AWS S3, as the prefix of the storage key)
ln$Artifact$filter(key__startswith = "my_datasets/")$df()

# query all artifacts ingested from a transform
artifacts <- ln$Artifact$filter(transform = transform)$all()

# query all artifacts ingested from a notebook with "intro" in the title
artifacts <- ln$Artifact$filter(
  transform__description__icontains = "intro"
)$all()

# search artifacts
ln$Artifact$search("iris")$df()

# search transforms
ln$Transform$search("intro")$df()

# look up records with auto-complete
ulabels <- ln$ULabel$lookup()
```

# Features & labels

See https://docs.lamin.ai/introduction#features-labels

```{r features}
# create & save a typed label
experiment_type <- ln$ULabel(name = "InVitroStudy", is_type = TRUE)$save()
my_experiment <- ln$ULabel(name = "My experiment", type = experiment_type)$save()

# annotate the artifact with a label
artifact$ulabels$add(my_experiment)

# describe the artifact
artifact$describe()

ln$Artifact$filter(ulabels = my_experiment)$df()

bt <- import_module("bionty")

# create a cell type label from the source ontology
cell_type <- bt$CellType$from_source(name = "effector T cell")$save()

# annotate the artifact with a cell type
artifact$cell_types$add(cell_type)

# describe the artifact
artifact$describe()

# define the "temperature" & "experiment" features
ln$Feature(name = "temperature", dtype = "float")$save()
ln$Feature(name = "experiment", dtype = ln$ULabel)$save()

# annotate the artifact
artifact$features$add_values(
  list("temperature" = 21.6, "experiment" = "My experiment")
)

# describe the artifact
artifact$describe()
```

# Curate datasets

See https://docs.lamin.ai/introduction#curate-datasets

```{r curate}
# define valid labels
perturbation_type <- ln$ULabel(name = "Perturbation", is_type = TRUE)$save()
ln$ULabel(name = "DMSO", type = perturbation_type)$save()
ln$ULabel(name = "IFNG", type = perturbation_type)$save()

# define the schema
schema <- ln$Schema(
  name = "My DataFrame schema",
  features = list(
    ln$Feature(name = "perturbation", dtype = ln$ULabel)$save(),
    ln$Feature(name = "cell_type_by_model", dtype = bt$CellType)$save()
  )
)$save()

# create a curator
curator <- ln$curators$DataFrameCurator(df, schema)

# save curated artifact
artifact <- curator$save_artifact(key = "my_curated_dataset.parquet")  # calls .validate()

# see the parsed annotations
artifact$describe()

# query for a ulabel that was parsed from the dataset
ln$Artifact$get(ulabels__name = "IFNG")

curator <- ln$curators$DataFrameCurator(df_typo, schema)

# validate the dataset
tryCatch(
  curator$validate(),
  error = function(err) {
    cat(conditionMessage(err))
  }
)
```

# Manage biological registries

See https://docs.lamin.ai/introduction#manage-biological-registries

```{r registries}
bt <- import_module("bionty")

cell_types <- bt$CellType$public()
cell_types

cell_types$search("gamma-delta T cell") |> head(2)

# define var schema
var_schema <- ln$Schema(
  name = "my_var_schema",
  itype = bt$Gene$ensembl_gene_id,
  dtype = "int"
)$save()

# define composite schema
anndata_schema <- ln$Schema(
  name = "my_anndata_schema",
  otype = "AnnData",
  components = list("obs" = schema, "var" = var_schema)
)$save()

ad <- import_module("anndata")

# store the dataset as an AnnData object to distinguish data from metadata
adata <- ad$AnnData(df[, 1:3], obs = df[, 4:ncol(df)])

# save curated artifact
curator <- ln$curators$AnnDataCurator(adata, anndata_schema)
artifact <- curator$save_artifact(key = "my_datasets/my_rnaseq1.h5ad")
artifact$describe()

# get a lookup object for human genes
genes <- bt$Gene$filter(organism__name = "human")$lookup()
# query for all feature sets that contain CD8A
feature_sets <- ln$Schema$filter(genes = genes$cd8a)$all()
# write the query
ln$Artifact$filter(feature_sets__in = feature_sets)$df()

# create an ontology-coupled cell type record and save it
neuron <- bt$CellType$from_source(name = "neuron")$save()

# create a record to track a new cell state
new_cell_state <- bt$CellType(
  name = "my neuron cell state", description = "explains X"
)$save()

# express that it's a neuron state
new_cell_state$parents$add(neuron)

# view ontological hierarchy
new_cell_state$view_parents(distance = 2)
```

# Scale learning

See https://docs.lamin.ai/introduction#scale-learning

```{r scale}
# a new dataset
df2 <- ln$core$datasets$small_dataset2(otype = "DataFrame")
adata <- ad$AnnData(df2[, 1:3], obs = df2[, 4:ncol(df2)])
curator <- ln$curators$AnnDataCurator(adata, anndata_schema)
artifact2 <- curator$save_artifact(key = "my_datasets/my_rnaseq2.h5ad")

collection <- ln$Collection(list(artifact, artifact2), key = "my-RNA-seq-collection")$save()
collection$describe()
collection$view_lineage()

# if it's small enough, you can load the entire collection into memory as if it was one
collection$load()

# typically, it's too big, hence, open it for streaming (if the backend allows it):  collection.open()

# or iterate over its artifacts
collection$artifacts$all()

# or look at a DataFrame listing the artifacts
collection$artifacts$df()
```

# Finish

```{r finish}
ln$finish()
```
